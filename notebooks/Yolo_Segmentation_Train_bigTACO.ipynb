{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJQb7ylX2vHr"
      },
      "outputs": [],
      "source": [
        "# Yolo_Segmentation_Train_bigTACO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnR789Ue7ASW"
      },
      "source": [
        "# 1. Preparation\n",
        " - import dependencies and download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKJBhdHKijMG"
      },
      "outputs": [],
      "source": [
        "mount_drive = True\n",
        "reduced = True\n",
        "bbox = False #bbox=True for bounding box detection, bbox=False for segmentation (mask) detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D7J191IYwp8"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TTOdqkAk_Ad"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%rm -rf /content/*\n",
        "!git clone https://github.com/ultralytics/yolov5 \n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt wandb\n",
        "!pip install --upgrade albumentations\n",
        "%cd ..\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBHHieZsCbGS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/scikit-multilearn/scikit-multilearn/master/skmultilearn/model_selection/iterative_stratification.py\n",
        "from iterative_stratification import *\n",
        "from PIL import Image, ExifTags\n",
        "from pycocotools.coco import COCO\n",
        "from matplotlib.patches import Polygon, Rectangle\n",
        "from matplotlib.collections import PatchCollection\n",
        "import colorsys\n",
        "import random\n",
        "import pylab\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "from tqdm import tqdm\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0nSxY0wdrr2"
      },
      "outputs": [],
      "source": [
        "if mount_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/gdrive')\n",
        "\n",
        "  # get images\n",
        "  if not os.path.isfile('/content/image.zip'):\n",
        "    %cp /gdrive/MyDrive/bigTACO_0119.zip /content/image.zip "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wb-HOcgUubzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMKb-KDK3kta"
      },
      "outputs": [],
      "source": [
        "!unzip -qq ./image.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r28C3oJowTBr"
      },
      "outputs": [],
      "source": [
        "!mkdir ./dataset\n",
        "%mv /content/bigTACO/* /content/dataset/ && rm -rf ./bigTACO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbwKD15fKpfa"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/pedropro/TACO/master/data/annotations.json\n",
        "!wget https://raw.githubusercontent.com/pedropro/TACO/master/data/annotations_unofficial.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCoUjuX-7M0s"
      },
      "source": [
        "# 2. Data pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrNbAFxrALVY"
      },
      "source": [
        "## get labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_LKRUfd769j"
      },
      "outputs": [],
      "source": [
        "base_anno = './annotations.json'\n",
        "unof_anno =  './annotations_unofficial.json'\n",
        "\n",
        "base_coco_anno = COCO(annotation_file=base_anno)\n",
        "unof_coco_anno = COCO(annotation_file=unof_anno)\n",
        "\n",
        "with open(base_anno, 'r') as f:\n",
        "    base_anno = json.loads(f.read())\n",
        "\n",
        "with open(unof_anno, 'r') as f:\n",
        "    unof_anno = json.loads(f.read())   \n",
        "\n",
        "# get the \"id to superid\" relationship\n",
        "supercat_cat_id = [[i['supercategory'],i['name'],i['id']] for i in base_anno['categories']]\n",
        "id_supercat = {i[2]:i[0] for i in supercat_cat_id}\n",
        "super_id = {j:i for i,j in enumerate(list(dict.fromkeys([(j) for i,j in enumerate([i['supercategory'] for i in base_anno['categories']])])))}\n",
        "id_superid = {i:super_id[id_supercat[i]] for i in range(60)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvecn4DP7tVg"
      },
      "source": [
        "## filter and reorganize labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZOhlyil76_s"
      },
      "outputs": [],
      "source": [
        "dst = \"./dataset\"\n",
        "\n",
        "%rm -rf ./dataset/labels #reset labels\n",
        "!mkdir ./dataset/labels\n",
        "\n",
        "bbox_thold = 50*50 # threshold of bbox under which bbox will be discarded for being too small\n",
        "                  # threshold = width*height, e.g. 40*40 = 1600 pixels\n",
        "\n",
        "base_imgs = base_anno['images']\n",
        "unof_imgs = unof_anno['images']\n",
        "\n",
        "counter = 0\n",
        "\n",
        "bad_annotation=[]\n",
        "for img in tqdm(base_imgs+unof_imgs):\n",
        "  height = img['height']\n",
        "  width = img['width']\n",
        "\n",
        "  # reorganize images\n",
        "  img_id = img['id']\n",
        "  if counter>=1500: img_id+=1500\n",
        "\n",
        "  # reorganize annotations\n",
        "  img_id_ = img['id']\n",
        "  if counter<1500: \n",
        "    annotation_ids = base_coco_anno.getAnnIds(img_id_)\n",
        "  else: \n",
        "    annotation_ids = unof_coco_anno.getAnnIds(img_id_)\n",
        "\n",
        "  if len(annotation_ids) == 0:\n",
        "    continue\n",
        "\n",
        "  with open(dst+'/labels/'+str(img_id)+'.txt', mode='w') as fp:\n",
        "    if counter<1500: annotations = base_coco_anno.loadAnns(annotation_ids)\n",
        "    else: annotations = unof_coco_anno.loadAnns(annotation_ids)\n",
        "    lines = ''\n",
        "    for annotation in annotations:\n",
        "      class_ = copy.copy(annotation['category_id'])\n",
        "      if reduced: class_ = id_superid[class_]\n",
        "      box = copy.copy(annotation['bbox'])\n",
        "      try:\n",
        "        seg = copy.copy(annotation['segmentation'])[0]\n",
        "      except:\n",
        "        seg=[]\n",
        "        bad_annotation.append([img_id,annotation])\n",
        "\n",
        "      # some annotations have basically no width / height (extremely small), skip them\n",
        "      if box[2] * box[3] < bbox_thold:\n",
        "        #print('bbox too small, skipped. skipped bbox is in image ID:'+ str(img_id)) #uncomment below line to see which images have bbox skipped\n",
        "        continue\n",
        "\n",
        "      segmentation = []\n",
        "      for id,x in enumerate(seg):\n",
        "        # standardize to 0-1\n",
        "        if id%2 ==0: x/=width\n",
        "        else: x/=height\n",
        "        segmentation.append(x)\n",
        "\n",
        "      lines += str(class_)\n",
        "      for i in segmentation:\n",
        "        lines += ' ' + str(i)\n",
        "      lines = lines+ '\\n'\n",
        "    fp.writelines(lines)\n",
        "\n",
        "  counter+=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHGU6Xh5RCtr"
      },
      "source": [
        "We found that some annotation (currently 15) (bbox & segmentation) are incorrect.\n",
        "\n",
        "`bad_annotation` keeps a track of them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLI31SfrRLp6"
      },
      "outputs": [],
      "source": [
        "len(bad_annotation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN_F5hknQSwG"
      },
      "outputs": [],
      "source": [
        "# for example:\n",
        "bad_annotation[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqGl0n3iAQjF"
      },
      "source": [
        "## train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPFCzX31IGBq"
      },
      "outputs": [],
      "source": [
        "nr_imgs=None\n",
        "for root, dirnames, filenames in os.walk('./dataset/labels/'):\n",
        "  nr_imgs = len(filenames)\n",
        "  break\n",
        "print('Number of all images:\\n'+str(nr_imgs))\n",
        "\n",
        "if reduced: \n",
        "  nr_class = 28\n",
        "else: nr_class = 60\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "En4L_nlIrrfJ"
      },
      "outputs": [],
      "source": [
        "xy = {}\n",
        "for i in tqdm(range(nr_imgs)):\n",
        "  try: \n",
        "    X = open('./dataset/labels/'+str(i)+'.txt','r')\n",
        "    lines = X.readlines()\n",
        "    classes = [int(line.split()[0]) for line in lines]\n",
        "    x = pd.DataFrame([Counter(classes)],columns=[*range(nr_class)]).fillna(0).astype(int).iloc[[0]].squeeze().tolist()\n",
        "    y=i\n",
        "    xy[y]=x\n",
        "\n",
        "  except: \n",
        "    print('\\nimage id number '+str(i)+' skipped due to no label found')\n",
        "    pass\n",
        "X = pd.DataFrame.from_dict(xy, orient='index')\n",
        "\n",
        "y = xy.keys()\n",
        "one_hot_y = pd.get_dummies(y)\n",
        "\n",
        "## train test split\n",
        "'''\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "'''\n",
        "\n",
        "np.random.seed(123) # sk-multilearn is based on sk, sk uses np random state. \n",
        "                  # so, setting np random seed will clamp the results of iterative_train_test_split\n",
        "\n",
        "X_train, y_train, X_temp, y_temp = iterative_train_test_split(X.values, one_hot_y.values, test_size = 0.5)\n",
        "X_train1, y_train1, X_val, y_val = iterative_train_test_split(X_temp, y_temp, test_size = 0.5)\n",
        "X_val, y_val,X_test,y_test = iterative_train_test_split(X_val, y_val, test_size = 0.5)\n",
        "\n",
        "# ISSUE: in this environment, any test_size!= 0.5 results in nothing in testing set. \n",
        "# therefore train/val/test split is roughly .75, .125, .125\n",
        "\n",
        "y_train = np.vstack((y_train,y_train1))\n",
        "train_ids,val_ids,test_ids = pd.DataFrame(y_train,columns = y).idxmax(axis=1).tolist(),\\\n",
        "                            pd.DataFrame(y_val,columns = y).idxmax(axis=1).tolist(),\\\n",
        "                            pd.DataFrame(y_test,columns = y).idxmax(axis=1).tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FrKhsOnTt2-i"
      },
      "outputs": [],
      "source": [
        "# check that no intersection\n",
        "set(train_ids).intersection(set(val_ids)), set(train_ids).intersection(set(test_ids)), set(val_ids).intersection(set(test_ids)), "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gBD-kJzt4fl"
      },
      "outputs": [],
      "source": [
        "# check total number of img_ids\n",
        "len(set(train_ids).union(set(val_ids)).union(set(test_ids)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eHpn_02tTqL"
      },
      "outputs": [],
      "source": [
        "# Visual check of train-test split\n",
        "\n",
        "def list_add(list1, list2): return [sum(x) for x in zip(list1, list2)]\n",
        "def vis(img_id_list):\n",
        "  vis=[0]*nr_class\n",
        "  for i in img_id_list:\n",
        "    X = open('./dataset/labels/'+str(i)+'.txt','r')\n",
        "    lines = X.readlines()\n",
        "    classes = [int(line.split()[0]) for line in lines]\n",
        "    x_ = pd.DataFrame([Counter(classes)],columns=[*range(nr_class)]).fillna(0).astype(int).iloc[[0]].squeeze().tolist()\n",
        "    vis=list_add(vis,x_)\n",
        "  return vis\n",
        "\n",
        "from matplotlib.pyplot import figure\n",
        "figure(figsize=(12, 8), dpi=80)\n",
        "\n",
        "plt.bar([*range(nr_class)],vis(train_ids), width = 1, label = 'Train')\n",
        "plt.bar([*range(nr_class)],vis(val_ids), width = 1, label = 'Val',alpha = 0.5)\n",
        "plt.bar([*range(nr_class)],vis(test_ids), width = 1, label = 'Test',alpha = 0.5)\n",
        "\n",
        "plt.xticks([*range(nr_class)],rotation = 75)\n",
        "plt.xlabel(\"Class_id\")\n",
        "plt.ylabel(\"Number of occurrence\")\n",
        "plt.title(\"Class distribution in Train/Val/Test sets\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S96FWSElHY9d"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "def move_helper(ids, desti):\n",
        "  for id in ids:\n",
        "    img_name = os.path.join( './dataset/images', str(id)+'.jpg' )\n",
        "    lbl_name = os.path.join( './dataset/labels', str(id)+'.txt' )\n",
        "    # print(img_name)\n",
        "    if os.path.isfile(img_name):\n",
        "        shutil.copy( img_name, './dataset/images/'+desti)\n",
        "        shutil.copy( lbl_name, './dataset/labels/'+desti)\n",
        "    else :\n",
        "        print('WARNING: file does not exist', img_name)\n",
        "\n",
        "!mkdir dataset/images/{train,val,test}\n",
        "!mkdir dataset/labels/{train,val,test}\n",
        "\n",
        "move_helper(test_ids,'test')\n",
        "move_helper(train_ids,'train')\n",
        "move_helper(val_ids,'val')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFIfSUyp7Ubg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yn14H2jt7VL7"
      },
      "source": [
        "# 3. Hyper-parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdMrwEgnB9C4"
      },
      "outputs": [],
      "source": [
        "%cd ./yolov5\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evH7jgs5Dnj7"
      },
      "outputs": [],
      "source": [
        "#@title data yml\n",
        "\n",
        "if reduced == True:\n",
        "\n",
        "  with open('/content/yolov5/data/TACO.yaml', mode='w') as fp:\n",
        "    lines = '''path: ../dataset  # dataset root dir\n",
        "train: images/train  # train images \n",
        "val: images/val  # val images \n",
        "test: images/test # test images (optional)\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: Aluminium foil\n",
        "  1: Battery\n",
        "  2: Blister pack\n",
        "  3: Bottle\n",
        "  4: Bottle cap\n",
        "  5: Broken glass\n",
        "  6: Can\n",
        "  7: Carton\n",
        "  8: Cup\n",
        "  9: Food waste\n",
        "  10: Glass jar\n",
        "  11: Lid\n",
        "  12: Other plastic\n",
        "  13: Paper\n",
        "  14: Paper bag\n",
        "  15: Plastic bag & wrapper\n",
        "  16: Plastic container\n",
        "  17: Plastic glooves\n",
        "  18: Plastic utensils\n",
        "  19: Pop tab\n",
        "  20: Rope & strings\n",
        "  21: Scrap metal\n",
        "  22: Shoe\n",
        "  23: Squeezable tube\n",
        "  24: Straw\n",
        "  25: Styrofoam piece\n",
        "  26: Unlabeled litter\n",
        "  27: Cigarette'''\n",
        "    fp.writelines(lines)\n",
        "\n",
        "else: \n",
        "  with open('/content/yolov5/data/TACO.yaml', mode='w') as fp:\n",
        "    lines = '''path: ../dataset  # dataset root dir\n",
        "train: images/train  # train images (relative to 'path') 128 images\n",
        "val: images/val  # val images (relative to 'path') 128 images\n",
        "test: images/test # test images (optional)\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: Aluminium foil\n",
        "  1: Battery\n",
        "  2: Aluminium blister pack\n",
        "  3: Carded blister pack\n",
        "  4: Other plastic bottle\n",
        "  5: Clear plastic bottle\n",
        "  6: Glass bottle\n",
        "  7: Plastic bottle cap\n",
        "  8: Metal bottle cap\n",
        "  9: Broken glass\n",
        "  10: Food Can\n",
        "  11: Aerosol\n",
        "  12: Drink can\n",
        "  13: Toilet tube\n",
        "  14: Other carton\n",
        "  15: Egg carton\n",
        "  16: Drink carton\n",
        "  17: Corrugated carton\n",
        "  18: Meal carton\n",
        "  19: Pizza box\n",
        "  20: Paper cup\n",
        "  21: Disposable plastic cup\n",
        "  22: Foam cup\n",
        "  23: Glass cup\n",
        "  24: Other plastic cup\n",
        "  25: Food waste\n",
        "  26: Glass jar\n",
        "  27: Plastic lid\n",
        "  28: Metal lid\n",
        "  29: Other plastic\n",
        "  30: Magazine paper\n",
        "  31: Tissues\n",
        "  32: Wrapping paper\n",
        "  33: Normal paper\n",
        "  34: Paper bag\n",
        "  35: Plastified paper bag\n",
        "  36: Plastic film\n",
        "  37: Six pack rings\n",
        "  38: Garbage bag\n",
        "  39: Other plastic wrapper\n",
        "  40: Single-use carrier bag\n",
        "  41: Polypropylene bag\n",
        "  42: Crisp packet\n",
        "  43: Spread tub\n",
        "  44: Tupperware\n",
        "  45: Disposable food container\n",
        "  46: Foam food container\n",
        "  47: Other plastic container\n",
        "  48: Plastic glooves\n",
        "  49: Plastic utensils\n",
        "  50: Pop tab\n",
        "  51: Rope & strings\n",
        "  52: Scrap metal\n",
        "  53: Shoe\n",
        "  54: Squeezable tube\n",
        "  55: Plastic straw\n",
        "  56: Paper straw\n",
        "  57: Styrofoam piece\n",
        "  58: Unlabeled litter\n",
        "  59: Cigarette'''\n",
        "    fp.writelines(lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyDYQ3QBe9yh"
      },
      "outputs": [],
      "source": [
        "#@title hyperparameter 1\n",
        "\n",
        "with open('/content/yolov5/utils/metrics.py', mode='w') as fp:\n",
        "  lines = \"\"\"\n",
        "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
        "\n",
        "import math\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from utils import TryExcept, threaded\n",
        "\n",
        "\n",
        "def fitness(x):\n",
        "    # Model fitness as a weighted combination of metrics\n",
        "    w = [0.0, 0.6, 0.4, 0.0]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]\n",
        "    return (x[:, :4] * w).sum(1)\n",
        "\n",
        "\n",
        "def smooth(y, f=0.05):\n",
        "    # Box filter of fraction f\n",
        "    nf = round(len(y) * f * 2) // 2 + 1  # number of filter elements (must be odd)\n",
        "    p = np.ones(nf // 2)  # ones padding\n",
        "    yp = np.concatenate((p * y[0], y, p * y[-1]), 0)  # y padded\n",
        "    return np.convolve(yp, np.ones(nf) / nf, mode='valid')  # y-smoothed\n",
        "\n",
        "\n",
        "def ap_per_class(tp, conf, pred_cls, target_cls, plot=False, save_dir='.', names=(), eps=1e-16, prefix=\"\"):\n",
        "\n",
        "    # Sort by objectness\n",
        "    i = np.argsort(-conf)\n",
        "    tp, conf, pred_cls = tp[i], conf[i], pred_cls[i]\n",
        "\n",
        "    # Find unique classes\n",
        "    unique_classes, nt = np.unique(target_cls, return_counts=True)\n",
        "    nc = unique_classes.shape[0]  # number of classes, number of detections\n",
        "\n",
        "    # Create Precision-Recall curve and compute AP for each class\n",
        "    px, py = np.linspace(0, 1, 1000), []  # for plotting\n",
        "    ap, p, r = np.zeros((nc, tp.shape[1])), np.zeros((nc, 1000)), np.zeros((nc, 1000))\n",
        "    for ci, c in enumerate(unique_classes):\n",
        "        i = pred_cls == c\n",
        "        n_l = nt[ci]  # number of labels\n",
        "        n_p = i.sum()  # number of predictions\n",
        "        if n_p == 0 or n_l == 0:\n",
        "            continue\n",
        "\n",
        "        # Accumulate FPs and TPs\n",
        "        fpc = (1 - tp[i]).cumsum(0)\n",
        "        tpc = tp[i].cumsum(0)\n",
        "\n",
        "        # Recall\n",
        "        recall = tpc / (n_l + eps)  # recall curve\n",
        "        r[ci] = np.interp(-px, -conf[i], recall[:, 0], left=0)  # negative x, xp because xp decreases\n",
        "\n",
        "        # Precision\n",
        "        precision = tpc / (tpc + fpc)  # precision curve\n",
        "        p[ci] = np.interp(-px, -conf[i], precision[:, 0], left=1)  # p at pr_score\n",
        "\n",
        "        # AP from recall-precision curve\n",
        "        for j in range(tp.shape[1]):\n",
        "            ap[ci, j], mpre, mrec = compute_ap(recall[:, j], precision[:, j])\n",
        "            if plot and j == 0:\n",
        "                py.append(np.interp(px, mrec, mpre))  # precision at mAP@0.5\n",
        "\n",
        "    # Compute F1 (harmonic mean of precision and recall)\n",
        "    f1 = 2 * p * r / (p + r + eps)\n",
        "    names = [v for k, v in names.items() if k in unique_classes]  # list: only classes that have data\n",
        "    names = dict(enumerate(names))  # to dict\n",
        "    if plot:\n",
        "        plot_pr_curve(px, py, ap, Path(save_dir) / f'{prefix}PR_curve.png', names)\n",
        "        plot_mc_curve(px, f1, Path(save_dir) / f'{prefix}F1_curve.png', names, ylabel='F1')\n",
        "        plot_mc_curve(px, p, Path(save_dir) / f'{prefix}P_curve.png', names, ylabel='Precision')\n",
        "        plot_mc_curve(px, r, Path(save_dir) / f'{prefix}R_curve.png', names, ylabel='Recall')\n",
        "\n",
        "    i = smooth(f1.mean(0), 0.1).argmax()  # max F1 index\n",
        "    p, r, f1 = p[:, i], r[:, i], f1[:, i]\n",
        "    tp = (r * nt).round()  # true positives\n",
        "    fp = (tp / (p + eps) - tp).round()  # false positives\n",
        "    return tp, fp, p, r, f1, ap, unique_classes.astype(int)\n",
        "\n",
        "\n",
        "def compute_ap(recall, precision):\n",
        "\n",
        "\n",
        "    # Append sentinel values to beginning and end\n",
        "    mrec = np.concatenate(([0.0], recall, [1.0]))\n",
        "    mpre = np.concatenate(([1.0], precision, [0.0]))\n",
        "\n",
        "    # Compute the precision envelope\n",
        "    mpre = np.flip(np.maximum.accumulate(np.flip(mpre)))\n",
        "\n",
        "    # Integrate area under curve\n",
        "    method = 'interp'  # methods: 'continuous', 'interp'\n",
        "    if method == 'interp':\n",
        "        x = np.linspace(0, 1, 101)  # 101-point interp (COCO)\n",
        "        ap = np.trapz(np.interp(x, mrec, mpre), x)  # integrate\n",
        "    else:  # 'continuous'\n",
        "        i = np.where(mrec[1:] != mrec[:-1])[0]  # points where x axis (recall) changes\n",
        "        ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])  # area under curve\n",
        "\n",
        "    return ap, mpre, mrec\n",
        "\n",
        "\n",
        "class ConfusionMatrix:\n",
        "    # Updated version of https://github.com/kaanakan/object_detection_confusion_matrix\n",
        "    def __init__(self, nc, conf=0.25, iou_thres=0.45):\n",
        "        self.matrix = np.zeros((nc + 1, nc + 1))\n",
        "        self.nc = nc  # number of classes\n",
        "        self.conf = conf\n",
        "        self.iou_thres = iou_thres\n",
        "\n",
        "    def process_batch(self, detections, labels):\n",
        "\n",
        "        if detections is None:\n",
        "            gt_classes = labels.int()\n",
        "            for gc in gt_classes:\n",
        "                self.matrix[self.nc, gc] += 1  # background FN\n",
        "            return\n",
        "\n",
        "        detections = detections[detections[:, 4] > self.conf]\n",
        "        gt_classes = labels[:, 0].int()\n",
        "        detection_classes = detections[:, 5].int()\n",
        "        iou = box_iou(labels[:, 1:], detections[:, :4])\n",
        "\n",
        "        x = torch.where(iou > self.iou_thres)\n",
        "        if x[0].shape[0]:\n",
        "            matches = torch.cat((torch.stack(x, 1), iou[x[0], x[1]][:, None]), 1).cpu().numpy()\n",
        "            if x[0].shape[0] > 1:\n",
        "                matches = matches[matches[:, 2].argsort()[::-1]]\n",
        "                matches = matches[np.unique(matches[:, 1], return_index=True)[1]]\n",
        "                matches = matches[matches[:, 2].argsort()[::-1]]\n",
        "                matches = matches[np.unique(matches[:, 0], return_index=True)[1]]\n",
        "        else:\n",
        "            matches = np.zeros((0, 3))\n",
        "\n",
        "        n = matches.shape[0] > 0\n",
        "        m0, m1, _ = matches.transpose().astype(int)\n",
        "        for i, gc in enumerate(gt_classes):\n",
        "            j = m0 == i\n",
        "            if n and sum(j) == 1:\n",
        "                self.matrix[detection_classes[m1[j]], gc] += 1  # correct\n",
        "            else:\n",
        "                self.matrix[self.nc, gc] += 1  # true background\n",
        "\n",
        "        if n:\n",
        "            for i, dc in enumerate(detection_classes):\n",
        "                if not any(m1 == i):\n",
        "                    self.matrix[dc, self.nc] += 1  # predicted background\n",
        "\n",
        "    def matrix(self):\n",
        "        return self.matrix\n",
        "\n",
        "    def tp_fp(self):\n",
        "        tp = self.matrix.diagonal()  # true positives\n",
        "        fp = self.matrix.sum(1) - tp  # false positives\n",
        "        # fn = self.matrix.sum(0) - tp  # false negatives (missed detections)\n",
        "        return tp[:-1], fp[:-1]  # remove background class\n",
        "\n",
        "    @TryExcept('WARNING ⚠️ ConfusionMatrix plot failure')\n",
        "    def plot(self, normalize=True, save_dir='', names=()):\n",
        "        import seaborn as sn\n",
        "\n",
        "        array = self.matrix / ((self.matrix.sum(0).reshape(1, -1) + 1E-9) if normalize else 1)  # normalize columns\n",
        "        array[array < 0.005] = np.nan  # don't annotate (would appear as 0.00)\n",
        "\n",
        "        fig, ax = plt.subplots(1, 1, figsize=(12, 9), tight_layout=True)\n",
        "        nc, nn = self.nc, len(names)  # number of classes, names\n",
        "        sn.set(font_scale=1.0 if nc < 50 else 0.8)  # for label size\n",
        "        labels = (0 < nn < 99) and (nn == nc)  # apply names to ticklabels\n",
        "        ticklabels = (names + ['background']) if labels else \"auto\"\n",
        "        with warnings.catch_warnings():\n",
        "            warnings.simplefilter('ignore')  # suppress empty matrix RuntimeWarning: All-NaN slice encountered\n",
        "            sn.heatmap(array,\n",
        "                       ax=ax,\n",
        "                       annot=nc < 30,\n",
        "                       annot_kws={\n",
        "                           \"size\": 8},\n",
        "                       cmap='Blues',\n",
        "                       fmt='.2f',\n",
        "                       square=True,\n",
        "                       vmin=0.0,\n",
        "                       xticklabels=ticklabels,\n",
        "                       yticklabels=ticklabels).set_facecolor((1, 1, 1))\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_ylabel('Predicted')\n",
        "        ax.set_title('Confusion Matrix')\n",
        "        fig.savefig(Path(save_dir) / 'confusion_matrix.png', dpi=250)\n",
        "        plt.close(fig)\n",
        "\n",
        "    def print(self):\n",
        "        for i in range(self.nc + 1):\n",
        "            print(' '.join(map(str, self.matrix[i])))\n",
        "\n",
        "\n",
        "def bbox_iou(box1, box2, xywh=True, GIoU=False, DIoU=False, CIoU=False, eps=1e-7):\n",
        "    # Returns Intersection over Union (IoU) of box1(1,4) to box2(n,4)\n",
        "\n",
        "    # Get the coordinates of bounding boxes\n",
        "    if xywh:  # transform from xywh to xyxy\n",
        "        (x1, y1, w1, h1), (x2, y2, w2, h2) = box1.chunk(4, 1), box2.chunk(4, 1)\n",
        "        w1_, h1_, w2_, h2_ = w1 / 2, h1 / 2, w2 / 2, h2 / 2\n",
        "        b1_x1, b1_x2, b1_y1, b1_y2 = x1 - w1_, x1 + w1_, y1 - h1_, y1 + h1_\n",
        "        b2_x1, b2_x2, b2_y1, b2_y2 = x2 - w2_, x2 + w2_, y2 - h2_, y2 + h2_\n",
        "    else:  # x1, y1, x2, y2 = box1\n",
        "        b1_x1, b1_y1, b1_x2, b1_y2 = box1.chunk(4, 1)\n",
        "        b2_x1, b2_y1, b2_x2, b2_y2 = box2.chunk(4, 1)\n",
        "        w1, h1 = b1_x2 - b1_x1, b1_y2 - b1_y1\n",
        "        w2, h2 = b2_x2 - b2_x1, b2_y2 - b2_y1\n",
        "\n",
        "    # Intersection area\n",
        "    inter = (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0) * \\\n",
        "            (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)\n",
        "\n",
        "    # Union Area\n",
        "    union = w1 * h1 + w2 * h2 - inter + eps\n",
        "\n",
        "    # IoU\n",
        "    iou = inter / union\n",
        "    if CIoU or DIoU or GIoU:\n",
        "        cw = torch.max(b1_x2, b2_x2) - torch.min(b1_x1, b2_x1)  # convex (smallest enclosing box) width\n",
        "        ch = torch.max(b1_y2, b2_y2) - torch.min(b1_y1, b2_y1)  # convex height\n",
        "        if CIoU or DIoU:  # Distance or Complete IoU https://arxiv.org/abs/1911.08287v1\n",
        "            c2 = cw ** 2 + ch ** 2 + eps  # convex diagonal squared\n",
        "            rho2 = ((b2_x1 + b2_x2 - b1_x1 - b1_x2) ** 2 + (b2_y1 + b2_y2 - b1_y1 - b1_y2) ** 2) / 4  # center dist ** 2\n",
        "            if CIoU:  # https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47\n",
        "                v = (4 / math.pi ** 2) * torch.pow(torch.atan(w2 / (h2 + eps)) - torch.atan(w1 / (h1 + eps)), 2)\n",
        "                with torch.no_grad():\n",
        "                    alpha = v / (v - iou + (1 + eps))\n",
        "                return iou - (rho2 / c2 + v * alpha)  # CIoU\n",
        "            return iou - rho2 / c2  # DIoU\n",
        "        c_area = cw * ch + eps  # convex area\n",
        "        return iou - (c_area - union) / c_area  # GIoU https://arxiv.org/pdf/1902.09630.pdf\n",
        "    return iou  # IoU\n",
        "\n",
        "\n",
        "def box_area(box):\n",
        "    # box = xyxy(4,n)\n",
        "    return (box[2] - box[0]) * (box[3] - box[1])\n",
        "\n",
        "\n",
        "def box_iou(box1, box2, eps=1e-7):\n",
        "    # https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py\n",
        "\n",
        "    # inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)\n",
        "    (a1, a2), (b1, b2) = box1[:, None].chunk(2, 2), box2.chunk(2, 1)\n",
        "    inter = (torch.min(a2, b2) - torch.max(a1, b1)).clamp(0).prod(2)\n",
        "\n",
        "    # IoU = inter / (area1 + area2 - inter)\n",
        "    return inter / (box_area(box1.T)[:, None] + box_area(box2.T) - inter + eps)\n",
        "\n",
        "\n",
        "def bbox_ioa(box1, box2, eps=1e-7):\n",
        "\n",
        "\n",
        "    # Get the coordinates of bounding boxes\n",
        "    b1_x1, b1_y1, b1_x2, b1_y2 = box1\n",
        "    b2_x1, b2_y1, b2_x2, b2_y2 = box2.T\n",
        "\n",
        "    # Intersection area\n",
        "    inter_area = (np.minimum(b1_x2, b2_x2) - np.maximum(b1_x1, b2_x1)).clip(0) * \\\n",
        "                 (np.minimum(b1_y2, b2_y2) - np.maximum(b1_y1, b2_y1)).clip(0)\n",
        "\n",
        "    # box2 area\n",
        "    box2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1) + eps\n",
        "\n",
        "    # Intersection over box2 area\n",
        "    return inter_area / box2_area\n",
        "\n",
        "\n",
        "def wh_iou(wh1, wh2, eps=1e-7):\n",
        "    # Returns the nxm IoU matrix. wh1 is nx2, wh2 is mx2\n",
        "    wh1 = wh1[:, None]  # [N,1,2]\n",
        "    wh2 = wh2[None]  # [1,M,2]\n",
        "    inter = torch.min(wh1, wh2).prod(2)  # [N,M]\n",
        "    return inter / (wh1.prod(2) + wh2.prod(2) - inter + eps)  # iou = inter / (area1 + area2 - inter)\n",
        "\n",
        "\n",
        "# Plots ----------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "@threaded\n",
        "def plot_pr_curve(px, py, ap, save_dir=Path('pr_curve.png'), names=()):\n",
        "    # Precision-recall curve\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n",
        "    py = np.stack(py, axis=1)\n",
        "\n",
        "    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n",
        "        for i, y in enumerate(py.T):\n",
        "            ax.plot(px, y, linewidth=1, label=f'{names[i]} {ap[i, 0]:.3f}')  # plot(recall, precision)\n",
        "    else:\n",
        "        ax.plot(px, py, linewidth=1, color='grey')  # plot(recall, precision)\n",
        "\n",
        "    ax.plot(px, py.mean(1), linewidth=3, color='blue', label='all classes %.3f mAP@0.5' % ap[:, 0].mean())\n",
        "    ax.set_xlabel('Recall')\n",
        "    ax.set_ylabel('Precision')\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "    ax.set_title('Precision-Recall Curve')\n",
        "    fig.savefig(save_dir, dpi=250)\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "@threaded\n",
        "def plot_mc_curve(px, py, save_dir=Path('mc_curve.png'), names=(), xlabel='Confidence', ylabel='Metric'):\n",
        "    # Metric-confidence curve\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(9, 6), tight_layout=True)\n",
        "\n",
        "    if 0 < len(names) < 21:  # display per-class legend if < 21 classes\n",
        "        for i, y in enumerate(py):\n",
        "            ax.plot(px, y, linewidth=1, label=f'{names[i]}')  # plot(confidence, metric)\n",
        "    else:\n",
        "        ax.plot(px, py.T, linewidth=1, color='grey')  # plot(confidence, metric)\n",
        "\n",
        "    y = smooth(py.mean(0), 0.05)\n",
        "    ax.plot(px, y, linewidth=3, color='blue', label=f'all classes {y.max():.2f} at {px[y.argmax()]:.3f}')\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel(ylabel)\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(0, 1)\n",
        "    ax.legend(bbox_to_anchor=(1.04, 1), loc=\"upper left\")\n",
        "    ax.set_title(f'{ylabel}-Confidence Curve')\n",
        "    fig.savefig(save_dir, dpi=250)\n",
        "    plt.close(fig)\n",
        "\n",
        "\"\"\"\n",
        "  fp.writelines(lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KhrRVW9e91d"
      },
      "outputs": [],
      "source": [
        "#@title hyperparameter 2\n",
        "\n",
        "# define hypter-parameters\n",
        "with open('./data/hyps/hyps.yaml', mode='w') as fp:\n",
        "  lines = \"\"\"# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
        "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
        "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n",
        "\n",
        "lr0: 0.01  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
        "lrf: 0.01  # final OneCycleLR learning rate (lr0 * lrf)\n",
        "momentum: 0.937  # SGD momentum/Adam beta1\n",
        "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
        "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
        "warmup_momentum: 0.8  # warmup initial momentum\n",
        "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
        "box: 0.05  # box loss gain\n",
        "cls: 0.3  # cls loss gain\n",
        "cls_pw: 1.0  # cls BCELoss positive_weight\n",
        "obj: 0.7  # obj loss gain (scale with pixels)\n",
        "obj_pw: 1.0  # obj BCELoss positive_weight\n",
        "iou_t: 0.20  # IoU training threshold\n",
        "anchor_t: 4.0  # anchor-multiple threshold\n",
        "# anchors: 3  # anchors per output layer (0 to ignore)\n",
        "\n",
        "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
        "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
        "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
        "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
        "degrees: 10.0  # image rotation (+/- deg)\n",
        "translate: 0.1  # image translation (+/- fraction)\n",
        "scale: 0.9  # image scale (+/- gain)\n",
        "shear: 0.0  # image shear (+/- deg)\n",
        "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
        "flipud: 0.0  # image flip up-down (probability)\n",
        "fliplr: 0.5  # image flip left-right (probability)\n",
        "\n",
        "mosaic: 1.0  # image mosaic (probability)\n",
        "mixup: 0.1  # image mixup (probability)\n",
        "copy_paste: 0  # segment copy-paste (probability)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  fp.writelines(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmCjXPzW7anu"
      },
      "source": [
        "# 4. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KP4-17g9UwZ"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "!rm -rf runs/train-seg/*\n",
        "!wandb disabled\n",
        "\n",
        "!python segment/train.py --cache ram --weights yolov5x-seg.pt --data TACO.yaml --img 640 \\\n",
        "--batch-size 32 --epochs 20 --patience 70 --hyp hyps.yaml\n",
        "\n",
        "# epochs set to 20 for demonstration purposes. train more for real application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYzDbWIs7gZe"
      },
      "source": [
        "# 5. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWU7yiRACz95"
      },
      "outputs": [],
      "source": [
        "from utils.plots import plot_results \n",
        "plot_results('/content/yolov5/runs/train-seg/exp/results.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEY3GiSUD_qJ"
      },
      "outputs": [],
      "source": [
        "from IPython import display\n",
        "display.Image(\"/content/yolov5/runs/train-seg/exp/results.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQmKVrd5BWdt"
      },
      "outputs": [],
      "source": [
        "%rm -rf /gdrive/MyDrive/yolo_seg_bigTACO/\n",
        "%mkdir /gdrive/MyDrive/yolo_seg_bigTACO/\n",
        "%cp -r /content/yolov5/runs/train-seg/* /gdrive/MyDrive/yolo_seg_bigTACO/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "ZQ_3E8f90rBd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}